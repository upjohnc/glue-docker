FROM python:3.7-bullseye

ENV PYSPARK_PYTHON=python
ENV PYTHONPATH=/app/src

RUN mkdir /app
WORKDIR /app

RUN apt-get update && \
      apt-get install --no-install-recommends -y default-jdk scala wget vim software-properties-common \
      curl unzip libpq-dev build-essential libssl-dev libffi-dev zip\
      && apt-get clean \
      && rm -rf /var/lib/apt/lists/*

RUN git clone -b glue-2.0 https://github.com/awslabs/aws-glue-libs

RUN wget https://aws-glue-etl-artifacts.s3.amazonaws.com/glue-common/apache-maven-3.6.0-bin.tar.gz
RUN tar zxfv apache-maven-3.6.0-bin.tar.gz
RUN rm apache-maven-3.6.0-bin.tar.gz

ENV MAVEN_HOME=/app/apache-maven-3.6.0
ENV PATH=$PATH:$MAVEN_HOME/bin

RUN wget https://aws-glue-etl-artifacts.s3.amazonaws.com/glue-2.0/spark-2.4.3-bin-hadoop2.8.tgz
RUN tar zxfv spark-2.4.3-bin-hadoop2.8.tgz
ENV SPARK_HOME=/app/spark-2.4.3-bin-spark-2.4.3-bin-hadoop2.8
ENV PATH=$PATH:$SPARK_HOME/bin
ENV GLUE_HOME=/app/aws-glue-libs
ENV PATH=$PATH:$GLUE_HOME/bin

COPY docker/glue-setup.sh /app/aws-glue-libs/bin/glue-setup.sh
RUN cd /app/aws-glue-libs && sh bin/glue-setup.sh && cd /app # need to run as source to keep in the same shell (rather than in a sub-shell)

ENV PYTHONPATH="$SPARK_HOME/python/:$PYTHONPATH"
# the py4j version may change so this line needs to change with it
ENV PYTHONPATH="/app/spark-2.4.3-bin-spark-2.4.3-bin-hadoop2.8/python/lib/py4j-0.10.7-src.zip:$PYTHONPATH"
ENV PYTHONPATH="/app/aws-glue-libs/PyGlue.zip:$PYTHONPATH"
ENV SPARK_CONF_DIR=/app/aws-glue-libs/conf
